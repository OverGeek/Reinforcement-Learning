{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from vizdoom import *\n",
    "\n",
    "import random\n",
    "import time\n",
    "from skimage import transform\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os as os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WandB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is not necessary, comment all the code in this section.\n",
    "It's only to connect tensorflow model with wandb.ai\n",
    "\n",
    "Link: app.wandb.ai/dhruv/ddqnn-doom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\Anaconda\\envs\\deep_learning\\lib\\site-packages\\wandb\\tensorflow\\__init__.py:11: The name tf.train.summary_iterator is deprecated. Please use tf.compat.v1.train.summary_iterator instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/dhruv/ddqnn-doom\" target=\"_blank\">https://app.wandb.ai/dhruv/ddqnn-doom</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/dhruv/ddqnn-doom/runs/2ovuh283\" target=\"_blank\">https://app.wandb.ai/dhruv/ddqnn-doom/runs/2ovuh283</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.tensorflow import WandbHook\n",
    "\n",
    "wandb.init(project = 'ddqnn-doom', sync_tensorboard = True)\n",
    "\n",
    "\n",
    "wandb.config.epochs = 2000\n",
    "\n",
    "flags = tf.app.flags\n",
    "flags.DEFINE_string('data_dir', '/tmp/data', 'Data Directory')\n",
    "flags.DEFINE_integer('batch_size', 64, 'Batch size.')\n",
    "wandb.config.update(flags.FLAGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a game environment and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game has three possible actions\n",
    "\n",
    "1. Move left\n",
    "2. Move right\n",
    "3. Shoot\n",
    "4. Move forward\n",
    "5. Move backward\n",
    "6. Turn left\n",
    "7. Turn right\n",
    "\n",
    "The agent is rewarded points for each action and state\n",
    "\n",
    "1. Death penalty = -100\n",
    "2. Getting closer to vest = +dX\n",
    "3. Getting farther from vest = -dX\n",
    "\n",
    "The reward system will force the agent to reaach the vest as soon as possible.\n",
    "The reward system is preloaded in the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_environment():\n",
    "    game = DoomGame()\n",
    "    game.load_config(\"deadly_corridor.cfg\")\n",
    "    \n",
    "    game.set_doom_scenario_path(\"deadly_corridor.wad\")\n",
    "    \n",
    "    game.init()\n",
    "    \n",
    "    possible_actions = np.identity(7, dtype = int).tolist()\n",
    "    \n",
    "    return game, possible_actions\n",
    "\n",
    "def test_environment():\n",
    "    game = DoomGame()\n",
    "    game.load_config(\"deadly_corridor.cfg\")\n",
    "    game.set_doom_scenario_path(\"deadly_corridor.wad\")\n",
    "    game.init()\n",
    "    \n",
    "    actions = np.identity(7, dtype = int).tolist()\n",
    "    \n",
    "    episodes = 10\n",
    "    \n",
    "    for i in range(episodes):\n",
    "        game.new_episode()\n",
    "        \n",
    "        while not game.is_episode_finished():\n",
    "            state = game.get_state() \n",
    "            img = state.screen_buffer # Returns the frame from a game (RGB Frame)\n",
    "            misc = state.game_variables\n",
    "            action = random.choice(actions)\n",
    "            print(action)\n",
    "            reward = game.make_action(action)\n",
    "            print(\"reward: \",reward)\n",
    "            time.sleep(0.02)\n",
    "            \n",
    "        print(\"Result: \",game.get_total_reward())\n",
    "        time.sleep(2)\n",
    "    \n",
    "    game.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line below to make a test environment and check if game works fine\n",
    "\n",
    "# test_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the game frame\n",
    "\n",
    "def preprocess_frame(frame):\n",
    "    frame = np.moveaxis(frame, 0, -1) # Re-order to have frame in (Height, Width, Channels) order\n",
    "    frame = rgb2gray(frame)     # Color does not add any additional information so its computationally efficient to\n",
    "                                  # convert to grayscale\n",
    "#     plt.imshow(frame, cmap = 'gray')\n",
    "    cropped_frame = frame[15: -5, 20: -20]  # Cropping unecessary area from the frame\n",
    "    \n",
    "    normalized_frame = cropped_frame/ 255.\n",
    "    \n",
    "    preprocessed_frame = transform.resize(normalized_frame, [100, 120])\n",
    "    \n",
    "    return preprocessed_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "game, possible_actions = create_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_size = 4   # Stacking 4 frames to give a picture of motion to the model\n",
    "\n",
    "stacked_frames = deque([np.zeros((84, 84), dtype = np.int) for i in range(stack_size)], maxlen = stack_size)\n",
    "\n",
    "def stack_frames(stacked_frames, state, is_new_episode):\n",
    "    frame = preprocess_frame(state)\n",
    "    \n",
    "    # for first frame, stack it four times\n",
    "    if is_new_episode:\n",
    "        stacked_frames = deque([np.zeros((84, 84), dtype = np.int) for i in range(stack_size)], maxlen = stack_size)\n",
    "\n",
    "        for i in range(stack_size):\n",
    "            stacked_frames.append(frame)\n",
    "            \n",
    "        stacked_state = np.stack(stacked_frames, axis = 2)\n",
    "        \n",
    "    # if not the first frame, enqueue the latest frame and dequeue the oldest frame\n",
    "    else:\n",
    "        stacked_frames.append(frame)\n",
    "        stacked_state = np.stack(stacked_frames, axis = 2)\n",
    "        \n",
    "    return stacked_state, stacked_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_size = [100, 120, 4]  # Size of input to the model\n",
    "\n",
    "action_size = game.get_available_buttons_size()\n",
    "\n",
    "learning_rate = 0.00025\n",
    "\n",
    "total_episodes = 2000  # Total number of training games\n",
    "max_steps = 5000  # Maximum steps to be taken in a game\n",
    "batch_size = 128  # Batch size input to the model\n",
    "\n",
    "max_tau = 1000 # Step number at which we need to update our target network\n",
    "\n",
    "epsilon_start = 1.  # max exploration rate\n",
    "epsilon_end = 0.01  # min exploration rate\n",
    "decay_rate = 0.0005  # decay rate per game\n",
    "\n",
    "gamma = 0.95   #discount factor\n",
    "\n",
    "pretrain_length = 1000  # Initial memory size\n",
    "memory_size = 100000  # Maximum memory size\n",
    "\n",
    "training = False  # Boolen value to train or not\n",
    "render = True  # Boolean value to see the agent train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dueling Double Deep-Q-learning Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDDQNNet:\n",
    "    def __init__(self, state_size, action_size, learning_rate, name):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.name = name\n",
    "        \n",
    "        with tf.variable_scope(self.name):\n",
    "            self.inputs_ = tf.placeholder(tf.float32, [None, *state_size],\n",
    "                                         name = 'inputs')\n",
    "            self.actions_ = tf.placeholder(tf.float32, [None, action_size],\n",
    "                                         name = 'actions')\n",
    "            \n",
    "            self.target_Q = tf.placeholder(tf.float32, [None],\n",
    "                                          name = 'target')\n",
    "            \n",
    "            \n",
    "            self.conv1 = tf.layers.conv2d(inputs = self.inputs_,\n",
    "                                         filters = 32,\n",
    "                                         kernel_size = [8,8],\n",
    "                                         strides = [4,4],\n",
    "                                         padding = \"VALID\",\n",
    "                                          kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(),\n",
    "                                         name = \"conv1\")\n",
    "            \n",
    "            self.conv1_out = tf.nn.elu(self.conv1, name=\"conv1_out\")\n",
    "            \n",
    "            self.conv2 = tf.layers.conv2d(inputs = self.conv1_out,\n",
    "                                 filters = 64,\n",
    "                                 kernel_size = [4,4],\n",
    "                                 strides = [2,2],\n",
    "                                 padding = \"VALID\",\n",
    "                                kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(),\n",
    "                                 name = \"conv2\")\n",
    "\n",
    "            self.conv2_out = tf.nn.elu(self.conv2, name=\"conv2_out\")\n",
    "            \n",
    "            self.conv3 = tf.layers.conv2d(inputs = self.conv2_out,\n",
    "                                 filters = 128,\n",
    "                                 kernel_size = [4,4],\n",
    "                                 strides = [2,2],\n",
    "                                 padding = \"VALID\",\n",
    "                                kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(),\n",
    "                                 name = \"conv3\")\n",
    "\n",
    "            self.conv3_out = tf.nn.elu(self.conv3, name=\"conv3_out\")\n",
    "            \n",
    "            self.flatten = tf.layers.flatten(self.conv3_out)\n",
    "            \n",
    "            self.value_fc = tf.layers.dense(inputs = self.flatten,\n",
    "                                  units = 512,\n",
    "                                  activation = tf.nn.elu,\n",
    "                                       kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                name=\"value_fc\")\n",
    "            \n",
    "            self.value = tf.layers.dense(inputs = self.value_fc,\n",
    "                                        units = 1,\n",
    "                                        activation = None,\n",
    "                                        kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                name=\"value\")\n",
    "            \n",
    "            self.advantage_fc = tf.layers.dense(inputs = self.flatten,\n",
    "                                  units = 512,\n",
    "                                  activation = tf.nn.elu,\n",
    "                                       kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                name=\"advantage_fc\")\n",
    "            \n",
    "            self.advantage = tf.layers.dense(inputs = self.advantage_fc,\n",
    "                                        units = self.action_size,\n",
    "                                        activation = None,\n",
    "                                        kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                name=\"advantages\")\n",
    "            \n",
    "            self.output = self.value + tf.subtract(self.advantage, tf.reduce_mean(self.advantage, axis=1, keepdims=True))\n",
    "            \n",
    "            self.Q = tf.reduce_sum(tf.multiply(self.output, self.actions_), axis=1)\n",
    "                        \n",
    "            self.loss = tf.reduce_mean(tf.squared_difference(self.target_Q, self.Q))\n",
    "            \n",
    "            self.optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-9-d3c2e69631f7>:24: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F21B23E0C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F21B23E0C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F21B23E0C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F21B23E0C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F21B23E8C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F21B23E8C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F21B23E8C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F21B23E8C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F21B23E8C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F21B23E8C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F21B23E8C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F21B23E8C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From <ipython-input-9-d3c2e69631f7>:48: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F21B23E8C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F21B23E8C8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F21B23E8C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F21B23E8C8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From <ipython-input-9-d3c2e69631f7>:54: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F21B23E8C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F21B23E8C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F21B23E8C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F21B23E8C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F21B23E8C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F21B23E8C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F21B23E8C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F21B23E8C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F21B23E8C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F21B23E8C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F21B23E8C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F21B23E8C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F21B23E8C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F21B23E8C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F21B23E8C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F21B23E8C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F21C754548>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F21C754548>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F21C754548>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F21C754548>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F21CA74F88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F21CA74F88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F21CA74F88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F21CA74F88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F21C8D7A48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F21C8D7A48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F21C8D7A48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F21C8D7A48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F21C8D7A48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F21C8D7A48>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F21C8D7A48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F21C8D7A48>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F21C8D7A48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F21C8D7A48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F21C8D7A48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F21C8D7A48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F21C8D7A48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F21C8D7A48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F21C8D7A48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F21C8D7A48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F21C8D7A48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F21C8D7A48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F21C8D7A48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F21C8D7A48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F21C8D7A48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F21C8D7A48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F21C8D7A48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F21C8D7A48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "DQNetwork = DDDQNNet(state_size, action_size, learning_rate, name=\"DQNetwork\")\n",
    "\n",
    "TargetNetwork = DDDQNNet(state_size, action_size, learning_rate, name=\"TargetNetwork\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experience Replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory():\n",
    "    def __init__(self, max_size):\n",
    "        self.buffer = deque(maxlen = max_size)\n",
    "    \n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        buffer_size = len(self.buffer)\n",
    "        \n",
    "        index = np.random.choice(np.arange(buffer_size), size = batch_size,\n",
    "                                replace = False)\n",
    "        \n",
    "        return [self.buffer[i] for i in index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 147.01it/s]\n"
     ]
    }
   ],
   "source": [
    "memory = Memory(memory_size)\n",
    "\n",
    "game.new_episode()\n",
    "\n",
    "for i in tqdm(range(128)):\n",
    "    if i == 0:\n",
    "        state = game.get_state().screen_buffer\n",
    "        state, stacked_frames = stack_frames(stacked_frames, state, True)\n",
    "    \n",
    "    action = random.choice(possible_actions)\n",
    "    reward = game.make_action(action)\n",
    "    done = game.is_episode_finished()\n",
    "\n",
    "    if done:\n",
    "        next_state = np.zeros(state.shape)\n",
    "                \n",
    "        experience = state, action, reward, next_state, done\n",
    "        memory.add(experience)\n",
    "        \n",
    "        game.new_episode()\n",
    "        \n",
    "        state = game.get_state().screen_buffer\n",
    "        \n",
    "        state, stacked_frames = stack_frames(stacked_frames, state, True)\n",
    "        \n",
    "    else:\n",
    "        next_state = game.get_state().screen_buffer\n",
    "        next_state, stacked_frames = stack_frames(stacked_frames, next_state, False)\n",
    "        \n",
    "        experience = state, action, reward, next_state, done\n",
    "        memory.add(experience)\n",
    "        \n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter(\"/tensorboard/dddqn/1\")\n",
    "\n",
    "tf.summary.scalar(\"Loss\", DQNetwork.loss)\n",
    "\n",
    "write_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_action(epsilon_start, epsilon_end, decay_rate, decay_step, state, actions):\n",
    "    exp_exp_tradeoff = np.random.rand()\n",
    "    explore_probability = epsilon_end + (epsilon_start - epsilon_end)*np.exp(-decay_rate*decay_step)\n",
    "    \n",
    "    if explore_probability > exp_exp_tradeoff:\n",
    "        action = random.choice(possible_actions)\n",
    "    \n",
    "    else:\n",
    "        Qs = sess.run(DQNetwork.output, feed_dict = {DQNetwork.inputs_: state.reshape((1, *state.shape))})\n",
    "        \n",
    "        choice = np.argmax(Qs)\n",
    "        action = possible_actions[choice]\n",
    "        \n",
    "    return action, explore_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_target_graph():\n",
    "    from_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"DQNetwork\")\n",
    "    \n",
    "    to_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"TargetNetwork\")\n",
    "    \n",
    "    op_holder = []\n",
    "    \n",
    "    for from_var, to_var in zip(from_vars, to_vars):\n",
    "        op_holder.append(to_var.assign(from_var))\n",
    "        \n",
    "    return op_holder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "if training == True:\n",
    "    with tf.Session() as sess:\n",
    "        #Training from scratch: comment the line below and uncomment the line next to it\n",
    "        saver.restore(sess, \"./wandb/run-20200328_052741-36ojprom/model.ckpt\")\n",
    "\n",
    "        \n",
    "#         sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        decay_step = 0\n",
    "        \n",
    "        tau = 0\n",
    "        \n",
    "        game.init()\n",
    "        \n",
    "        update_target = update_target_graph()\n",
    "        sess.run(update_target)\n",
    "        \n",
    "        for episode in range(1, total_episodes+1):\n",
    "            step = 0\n",
    "            \n",
    "            episode_rewards = []\n",
    "            \n",
    "            game.new_episode()\n",
    "            state = game.get_state().screen_buffer\n",
    "            \n",
    "            state, stacked_frames = stack_frames(stacked_frames, state,\n",
    "                                                True)\n",
    "            \n",
    "            while step < max_steps:\n",
    "                step += 1\n",
    "                \n",
    "                decay_step += 1  # decaying exploration for each step in the game\n",
    "                \n",
    "                action, explore_probability = predict_action(epsilon_start,\n",
    "                                                            epsilon_end,\n",
    "                                                            decay_rate,\n",
    "                                                            decay_step,\n",
    "                                                            state,\n",
    "                                                            possible_actions)\n",
    "                \n",
    "                reward = game.make_action(action)\n",
    "                \n",
    "                done = game.is_episode_finished()\n",
    "                episode_rewards.append(reward)\n",
    "                \n",
    "                if done:\n",
    "                    next_state = np.zeros((84, 84), dtype = np.int)\n",
    "                    next_state, stacked_frames = stack_frames(stacked_frames,\n",
    "                                                             next_state,\n",
    "                                                             False)\n",
    "                    step = max_steps  # ending the current episode\n",
    "                    \n",
    "                    total_rewards = np.sum(episode_rewards)\n",
    "                    \n",
    "                    print(\"Episode: {}\".format(episode),\n",
    "                         \"Total reward: {}\".format(total_rewards),\n",
    "                         \"Training loss: {:.4f}\".format(loss),\n",
    "                         \"Explore Prob: {:.4f}\".format(explore_probability))\n",
    "                    \n",
    "                    wandb.log({'rewards': total_rewards, 'loss':loss, 'episode': episode})\n",
    "\n",
    "                    \n",
    "                    memory.add((state, action, reward, next_state, done))\n",
    "                    \n",
    "                else:\n",
    "                    next_state = game.get_state().screen_buffer\n",
    "                    next_state, stacked_frames = stack_frames(stacked_frames,\n",
    "                                                             next_state,\n",
    "                                                             False)\n",
    "                    \n",
    "                    memory.add((state, action, reward, next_state, done))\n",
    "                    \n",
    "                    state = next_state\n",
    "\n",
    "                batch = memory.sample(batch_size)\n",
    "                states_mb = np.array([each[0] for each in batch], ndmin = 3)\n",
    "                actions_mb = np.array([each[1] for each in batch])\n",
    "                rewards_mb = np.array([each[2] for each in batch])\n",
    "                next_states_mb = np.array([each[3] for each in batch], ndmin = 3)\n",
    "                dones_mb = np.array([each[4] for each in batch])\n",
    "    \n",
    "                target_Qs_batch = []\n",
    "                \n",
    "                Qs_next_state = sess.run(DQNetwork.output, feed_dict = {DQNetwork.inputs_: next_states_mb})\n",
    "                Q_target_next_state = sess.run(TargetNetwork.output, feed_dict = {TargetNetwork.inputs_: next_states_mb})\n",
    "                \n",
    "                for i in range(batch_size):\n",
    "                    terminal = dones_mb[i]\n",
    "                    \n",
    "                    action = np.argmax(Qs_next_state[i])\n",
    "                    \n",
    "                    if terminal:\n",
    "                        target_Qs_batch.append(rewards_mb[i])\n",
    "                        \n",
    "                    else:\n",
    "                        target = rewards_mb[i] + gamma*Q_target_next_state[i][action]\n",
    "                        target_Qs_batch.append(target)\n",
    "                        \n",
    "                targets_mb = np.array([each for each in target_Qs_batch])\n",
    "                \n",
    "                _, loss, absolute_errors = sess.run([DQNetwork.optimizer, DQNetwork.loss, DQNetwork.absolute_errors],\n",
    "                                  feed_dict = {DQNetwork.inputs_: states_mb,\n",
    "                                              DQNetwork.actions_: actions_mb,\n",
    "                                              DQNetwork.target_Q: targets_mb})\n",
    "#                                               DQNetwork.ISWeights_: ISWeights_mb})\n",
    "                \n",
    "                \n",
    "#                 memory.batch_update(tree_idx, absolute_errors)\n",
    "                \n",
    "                summary = sess.run(write_op, feed_dict = {DQNetwork.inputs_: states_mb,\n",
    "                                                         DQNetwork.target_Q: targets_mb,\n",
    "                                                         DQNetwork.actions_: actions_mb})\n",
    "#                                                         DQNetwork.ISWeights_: ISWeights_mb})\n",
    "                writer.add_summary(summary, episode)\n",
    "                writer.flush()\n",
    "                \n",
    "                if tau > max_tau:\n",
    "                    update_target = update_target_graph()\n",
    "                    sess.run(update_target)\n",
    "                    tau = 0\n",
    "                    print(\"Target Network Update\")\n",
    "                \n",
    "            if episode%2==0:\n",
    "                saver.save(sess, os.path.join(wandb.run.dir, \"model.ckpt\"))\n",
    "                print(\"Model Saved\")\n",
    "                \n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing - Agent plays the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./wandb/run-20200328_112139-1ut21yln/model.ckpt\n",
      "Game Score:  16.651336669921875\n",
      "Game Score:  41.46549987792969\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  26.246994018554688\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  7.335357666015625\n",
      "Game Score:  122.01123046875\n",
      "Game Score:  65.36900329589844\n",
      "Game Score:  30.322723388671875\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  150.4249725341797\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  100.24705505371094\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  46.72770690917969\n",
      "Game Score:  168.09585571289062\n",
      "Game Score:  38.225799560546875\n",
      "Game Score:  -1.5209808349609375\n",
      "Game Score:  -25.687347412109375\n",
      "Game Score:  -1.728729248046875\n",
      "Game Score:  4.4536590576171875\n",
      "Game Score:  67.384033203125\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  45.04173278808594\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  29.164718627929688\n",
      "Game Score:  195.05836486816406\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  196.8372344970703\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  133.158203125\n",
      "Game Score:  21.969284057617188\n",
      "Game Score:  -21.3302001953125\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  57.62432861328125\n",
      "Game Score:  72.24334716796875\n",
      "Game Score:  -23.58831787109375\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  37.72837829589844\n",
      "Game Score:  97.12474060058594\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  -10.0689697265625\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  162.74374389648438\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  -3.60137939453125\n",
      "Game Score:  139.00001525878906\n",
      "Game Score:  37.64424133300781\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  -18.414840698242188\n",
      "Game Score:  -7.7334136962890625\n",
      "Game Score:  -14.360153198242188\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  32.62126159667969\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  36.707672119140625\n",
      "Game Score:  -17.97454833984375\n",
      "Game Score:  -16.8055419921875\n",
      "Game Score:  -14.560989379882812\n",
      "Game Score:  52.26091003417969\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  14.713592529296875\n",
      "Game Score:  83.97810363769531\n",
      "Game Score:  137.82901000976562\n",
      "Game Score:  -9.564224243164062\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  4.8254547119140625\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  100.62275695800781\n",
      "Game Score:  48.419677734375\n",
      "Game Score:  -10.751953125\n",
      "Average Score:  73.55101501464844\n"
     ]
    }
   ],
   "source": [
    "test_episodes = 100\n",
    "average_score = 0\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    game, possible_actions = create_environment()\n",
    "    totalScore = 0\n",
    "    \n",
    "    saver.restore(sess, \"./wandb/run-20200328_112139-1ut21yln/model.ckpt\")\n",
    "    game.init()\n",
    "    \n",
    "    \n",
    "    for i in range(test_episodes):\n",
    "        game.new_episode()\n",
    "        \n",
    "        state = game.get_state().screen_buffer\n",
    "        state, stacked_frames = stack_frames(stacked_frames,\n",
    "                                            state, False)\n",
    "        \n",
    "        while not game.is_episode_finished():\n",
    "            Qs = sess.run(DQNetwork.output, feed_dict = {DQNetwork.inputs_: state.reshape((1, *state.shape))})\n",
    "            \n",
    "            choice = np.argmax(Qs)\n",
    "            action = possible_actions[choice]\n",
    "            \n",
    "            game.make_action(action)\n",
    "            done = game.is_episode_finished()\n",
    "            score = game.get_total_reward()\n",
    "                        \n",
    "            if done:\n",
    "                print(\"Game Score: \", score)\n",
    "                average_score += score\n",
    "                break\n",
    "            \n",
    "            next_state = game.get_state().screen_buffer\n",
    "            next_state, stacked_frames = stack_frames(stacked_frames,\n",
    "                                                     next_state, False)\n",
    "            \n",
    "            state = next_state\n",
    "            \n",
    "            score = game.get_total_reward()\n",
    "            \n",
    "    print(\"Average Score: \", average_score/test_episodes)\n",
    "    game.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
